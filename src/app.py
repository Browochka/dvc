import streamlit as st
import torch
import torch.nn as nn
from torchvision import models
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import json
import io


class SquirrelEfficientNet(nn.Module):
    def __init__(self, num_classes=5, pretrained=False):
        super().__init__()

        self.efficientnet = models.efficientnet_b0(pretrained=pretrained)

        for p in self.efficientnet.parameters():
            p.requires_grad = False

        in_features = self.efficientnet.classifier[1].in_features
        self.efficientnet.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.efficientnet(x)

st.set_page_config(
    page_title="üêøÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±–µ–ª–æ–∫",
    layout="centered"
)

st.title("üêøÔ∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–∏–¥–æ–≤ –±–µ–ª–æ–∫")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–ª–∫–∏")

st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

weights_file = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ (.pth)",
    type=["pth"]
)

classes_file = st.sidebar.file_uploader(
    "–§–∞–π–ª –∫–ª–∞—Å—Å–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, JSON)",
    type=["json"]
)

if classes_file:
    classes = json.load(classes_file)
else:
    classes = [
        "finlay",
        "karoling",
        "deppe",
        "gimalay",
        "prevost"
    ]

num_classes = len(classes)

@st.cache_resource
def load_model(weights_bytes):
    model = SquirrelEfficientNet(num_classes=num_classes)
    state_dict = torch.load(io.BytesIO(weights_bytes), map_location="cpu")
    model.load_state_dict(state_dict)
    model.eval()
    return model


model = None
if weights_file:
    model = load_model(weights_file.read())
    st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

image_file = st.file_uploader(
    "üì∑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–ª–∫–∏",
    type=["jpg", "jpeg", "png"]
)

transform = transforms.Compose([
    transforms.Resize(int(224 * 1.14)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

if image_file and model:
    image = Image.open(image_file).convert("RGB")
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    input_tensor = transform(image).unsqueeze(0)

    with torch.no_grad():
        logits = model(input_tensor)
        probs = F.softmax(logits, dim=1)[0]

    top_probs, top_idxs = torch.topk(probs, k=min(5, num_classes))

    st.subheader("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç")

    best_idx = top_idxs[0].item()
    best_prob = top_probs[0].item() * 100

    st.markdown(
        f"### **{classes[best_idx]}** ‚Äî `{best_prob:.1f}%`"
    )

    st.subheader("üìä –í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏")
    for i, idx in enumerate(top_idxs):
        st.progress(
            float(top_probs[i]),
            text=f"{classes[idx]} ‚Äî {top_probs[i]*100:.1f}%"
        )

elif image_file and not model:
    st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏")

else:
    st.info("‚¨ÖÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
